{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: David L. Parks  \n",
    "Prepared: Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What website you scraped, for what kind of products?  \n",
    "I scraped Trip Advisor for restaurants in Roanoke, Va.\n",
    "\n",
    "b. How you designed your scraping?  How you selected a list of products on the site?  \n",
    "I started my crawler on the page for restaurants in Roanoke. I then crawled across 5 pages of restaurants collecting 150 urls in a list. I used that list to fetch the page for each restaurant and scrape the latest reviews, up to 10, for each restaurant.  \n",
    "\n",
    "c. How you minimized your impact on the targeted website?  \n",
    "I changed the header to reflect my current web browser and I used time.sleep() with the numpy random int generator to randomly wait for 3 to 5 seconds between page requests.\n",
    "\n",
    "d. Any challenges you encountered and how you addressed them?  \n",
    "My initial crawler was getting a null pointer error because some restaurants only had one page of reviews. I fixed this issue by limiting the crawler to the first page of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the starting page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip Advisor reviews for restaurants in Roanoke, VA\n",
    "homepage = 'https://www.tripadvisor.com'\n",
    "url = 'https://www.tripadvisor.com/Restaurants-g58134-Roanoke_Virginia.html'\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crawl across 5 pages and scrape the url for each restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each iteration of the loop will randomly sleep from [3, 5] seconds\n",
    "for i in range(5):\n",
    "    page = requests.get(url, headers=header)\n",
    "    soup = bs.BeautifulSoup(page.text, 'html5lib')\n",
    "    restaurants = soup.find_all('a', {'class': 'restaurants-list-ListCell__restaurantName--2aSdo'})\n",
    "    restaurant_urls = restaurant_urls + [homepage + restaurant.get('href') for restaurant in restaurants]\n",
    "    url = homepage + soup.find('a', {'class': 'nav next rndBtn ui_button primary taLnk'}).get('href')\n",
    "    time.sleep(np.random.randint(3, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete any duplicate urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_urls = list(set(restaurant_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape up to 10 reviews from each restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each iteration of the loop sleeps for 1 second\n",
    "for restaurant_url in restaurant_urls:\n",
    "    page = requests.get(restaurant_url, headers=header)\n",
    "    soup = bs.BeautifulSoup(page.text, 'html5lib')\n",
    "    \n",
    "    # get restaurant name\n",
    "    name = soup.find('h1', {'class': 'ui_header h1'}).text\n",
    "    \n",
    "    # get urls of first page of reviews\n",
    "    reviews = soup.find_all('a', {'class': 'title'})\n",
    "    review_urls = [homepage + review.get('href') for review in reviews]\n",
    "    \n",
    "    # sleep for 1 second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # each iteration of the loop will randomly sleep from [3, 5] seconds\n",
    "    for review_url in review_urls:\n",
    "        page = requests.get(review_url, headers=header)\n",
    "        soup = bs.BeautifulSoup(page.text, 'html5lib')\n",
    "        rating = float(str(soup.find('div', {'class': 'rating reviewItemInline'}).contents[0])[-11:-10])\n",
    "        date = soup.find('span', {'class': 'ratingDate relativeDate'}).get('title')\n",
    "        author = soup.find('span', {'class': 'expand_inline scrname'}).text\n",
    "        text = soup.find('p', {'class': 'partial_entry'}).text\n",
    "        # strips extra space from the ends of the text and removes any non-ascii characters\n",
    "        text = text.strip().encode('ascii', 'ignore').decode()\n",
    "        restaurant_reviews.append([name, rating, date, author, text, review_url])\n",
    "        time.sleep(np.random.randint(3, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert restaurant review list into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_reviews = pd.DataFrame(restaurant_reviews,\n",
    "                                 columns=['Restaurant', 'Rating', 'Date', 'Author', 'Text', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataframe to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_reviews.to_csv('Homework08.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
